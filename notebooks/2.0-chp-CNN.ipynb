{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from bbox_plotter import yolo_to_corners\n",
        "from torchvision.ops import complete_box_iou_loss\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "from bbox_plotter import visualize_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ZebrafishDataset(Dataset):\n",
        "    def __init__(self, images_path, labels_path, transform=None):\n",
        "        self.images = np.load(images_path)\n",
        "        self.labels = np.load(labels_path)\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_path = \"D:\\Praharsha\\Code\\CAMZ\\data\\interim\\X_labelled_data.npy\"\n",
        "labels_path = \"D:\\Praharsha\\Code\\CAMZ\\data\\interim\\y_labelled_data.npy\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  \n",
        "    transforms.RandomRotation(degrees=30), \n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.02),  \n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.ToTensor()])\n",
        "dataset = ZebrafishDataset(images_path, labels_path, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * dataset.__len__())\n",
        "val_size = dataset.__len__() - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(dataset = val_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=128 * 26 * 26, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=4)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = self.pool3(torch.relu(self.conv3(x)))\n",
        "                \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        \n",
        "        return x\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CompleteBoxLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CompleteBoxLoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred_boxes, true_boxes, reduction):\n",
        "        ciou = complete_box_iou_loss(pred_boxes, true_boxes, reduction)\n",
        "        \n",
        "        return ciou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CNNModel()\n",
        "ciou_loss_function = CompleteBoxLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Initialize_writer(file_path):\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "    with open(file_path, mode='w', newline=\"\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['epoch', 'loss', 'val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, loss_function):\n",
        "    model.eval()\n",
        "    ciou_total_batch_loss = 0.0\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = yolo_to_corners(model(inputs), image_width=720, image_height=720)\n",
        "            labels = yolo_to_corners(labels, image_width=720, image_height=720)\n",
        "            \n",
        "            ciou_loss_per_batch = loss_function(outputs, labels, 'mean')\n",
        "            \n",
        "            ciou_total_batch_loss += ciou_loss_per_batch.item()\n",
        "        \n",
        "        \n",
        "        ciou_total_loss = ciou_total_batch_loss / len(val_loader)\n",
        "        \n",
        "        \n",
        "        print(f\"CIoU: {ciou_total_loss:.4f}\", end=\" \")\n",
        "        return ciou_total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, \n",
        "          loss_function,\n",
        "          history_csv_path, \n",
        "          save_model_checkpoint_path, num_epochs=1, patience=5):\n",
        "    \n",
        "    Initialize_writer(history_csv_path)\n",
        "    \n",
        "    \n",
        "    best_val_ciou_loss = float('inf')\n",
        "    \n",
        "    model.train()\n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        ciou_total_batch_loss = 0.0\n",
        "         \n",
        "        for inputs, labels in train_loader:\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            norm_labels = yolo_to_corners(labels, image_width=720, image_height=720)\n",
        "            outputs = yolo_to_corners(model(inputs), image_width=720, image_height=720)\n",
        "                     \n",
        "            \n",
        "            ciou_loss_per_batch = loss_function(outputs, norm_labels, 'mean')\n",
        "            \n",
        "            ciou_loss_per_batch.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            ciou_total_batch_loss += ciou_loss_per_batch.item()\n",
        "            \n",
        "        ciou_loss_per_epoch = ciou_total_batch_loss / len(train_loader)\n",
        "        \n",
        "        print(end='\\n')\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], CIoU: {ciou_loss_per_epoch:.4f}\", end=\" --- \")\n",
        "        print(f\"Validation for Epoch [{epoch+1}/{num_epochs}]\", end=\", \")\n",
        "        val_ciou_loss = validate(model, val_loader, loss_function)\n",
        "        \n",
        "        \n",
        "        if val_ciou_loss < best_val_ciou_loss:\n",
        "            best_val_ciou_loss = val_ciou_loss\n",
        "            checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "            print(\"\\n\")\n",
        "            print(f\"=========Saving Checkpoint======= at Epoch:[{epoch+1}/{num_epochs}]\", end=\"\\n\")\n",
        "            torch.save(checkpoint, save_model_checkpoint_path)\n",
        "            early_stopping = 0\n",
        "        \n",
        "        else:\n",
        "            early_stopping+=1 \n",
        "            \n",
        "\n",
        "        \n",
        "        with open(history_csv_path, mode='a', newline=\"\") as file:\n",
        "            loss_writer = csv.writer(file)\n",
        "            loss_writer.writerow([epoch+1, ciou_loss_per_epoch, val_ciou_loss])\n",
        "        \n",
        "        if early_stopping >= patience:\n",
        "            print(f\"Early stopping occured at {epoch+1}\")\n",
        "            break\n",
        "             \n",
        "    print(f\"The best Validation Loss is: {best_val_ciou_loss}\")\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_csv_file = \"D:\\Praharsha\\code\\CAMZ\\models\\model_history\\CNN_dataaug_logger.csv\"\n",
        "checkpoints_file = 'D:\\Praharsha\\code\\CAMZ\\models\\model_history\\CNN_checkpoint.pth.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_24384\\3547821039.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/100], CIoU: 1.0311 --- Validation for Epoch [1/100], CIoU: 1.0251 \n",
            "\n",
            "=========Saving Checkpoint======= at Epoch:[1/100]\n",
            "\n",
            "Epoch [2/100], CIoU: 1.0251 --- Validation for Epoch [2/100], CIoU: 1.0301 \n",
            "Epoch [3/100], CIoU: 1.0243 --- Validation for Epoch [3/100], CIoU: 1.0249 \n",
            "\n",
            "=========Saving Checkpoint======= at Epoch:[3/100]\n",
            "\n",
            "Epoch [4/100], CIoU: 1.0244 --- Validation for Epoch [4/100], CIoU: 1.0245 \n",
            "\n",
            "=========Saving Checkpoint======= at Epoch:[4/100]\n",
            "\n",
            "Epoch [5/100], CIoU: 1.0241 --- Validation for Epoch [5/100], CIoU: 1.0260 \n",
            "Epoch [6/100], CIoU: 1.0244 --- Validation for Epoch [6/100], CIoU: 1.0258 \n",
            "Epoch [7/100], CIoU: 1.0243 --- Validation for Epoch [7/100], CIoU: 1.0276 "
          ]
        }
      ],
      "source": [
        "train(model, train_loader, optimizer, ciou_loss_function,history_csv_path=history_csv_file,\n",
        "      save_model_checkpoint_path=checkpoints_file, num_epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from loss_curve_visualization import plot_loss_curves\n",
        "plot_loss_curves(\"D:\\Praharsha\\code\\CAMZ\\models\\model_history\\CNN_dataaug_logger.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint, architecture, optimizer):\n",
        "    print(\"loading checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    \n",
        "    model = architecture()\n",
        "    \n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    return model.eval()\n",
        "model = load_checkpoint(\"E:\\Code\\CAMZ\\models\\CNN_checkpoint.pth.tar\", CNNModel, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_path1 = r\"E:\\DIL\\Fish_classification_ViT\\data\\1Lcrop989.jpg.jpg\"\n",
        "image_path2 = r\"E:\\DIL\\Fish_classification_ViT\\data\\1Lcrop284.jpg.jpg\"\n",
        "image_path3 = r\"E:\\DIL\\Fish_classification_ViT\\data\\1Lcrop313.jpg.jpg\"\n",
        "\n",
        "visualize_prediction(image_path1, labels_path=r\"E:\\DIL\\Fish_classification_ViT\\data\\labels\",\n",
        "                     model=model)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_prediction(image_path2, labels_path=r\"E:\\DIL\\Fish_classification_ViT\\data\\labels\",\n",
        "                     model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_prediction(image_path3, labels_path=r\"E:\\DIL\\Fish_classification_ViT\\data\\labels\",\n",
        "                     model=model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
