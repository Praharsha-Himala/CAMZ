{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from bbox_plotter import yolo_to_corners\n",
    "from torchvision.ops import complete_box_iou_loss\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZebrafishDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None):\n",
    "        self.images = np.load(images_path)\n",
    "        self.labels = np.load(labels_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=128 * 26 * 26, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=4)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "                \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteBoxLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompleteBoxLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred_boxes, true_boxes, reduction):\n",
    "        ciou = complete_box_iou_loss(pred_boxes, true_boxes, reduction)\n",
    "        \n",
    "        return ciou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialize_writer(file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, mode='w', newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['epoch', 'loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"E:\\Code\\CAMZ\\data\\interim\\X_labelled_data.npy\"\n",
    "labels_path = \"E:\\Code\\CAMZ\\data\\interim\\y_labelled_data.npy\"\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset = ZebrafishDataset(images_path, labels_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 2\n",
    "num_epochs = 1\n",
    "loss_function = CompleteBoxLoss()\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f\"Fold: {fold+1}\")\n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_subsampler)\n",
    "    \n",
    "    model = CNNModel()\n",
    "    print(\"Resetting the model for upcoming training session\")\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    history_csv_path = f\"E:\\Code\\CAMZ\\models\\CrossValidation_history\\{fold+1}_history\"\n",
    "    Initialize_writer(history_csv_path)\n",
    "    \n",
    "    best_val_ciou_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #Training Pipeline\n",
    "        model.train()\n",
    "        ciou_total_batch_loss = 0.0\n",
    "         \n",
    "        for inputs, labels in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            norm_labels = yolo_to_corners(labels, image_width=720, image_height=720)\n",
    "            outputs = yolo_to_corners(model(inputs), image_width=720, image_height=720)\n",
    "                     \n",
    "            \n",
    "            ciou_loss_per_batch = loss_function(outputs, norm_labels, 'mean')\n",
    "            \n",
    "            ciou_loss_per_batch.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            ciou_total_batch_loss += ciou_loss_per_batch.item()\n",
    "            \n",
    "        ciou_loss_per_epoch = ciou_total_batch_loss / len(train_loader)\n",
    "        \n",
    "        print(end='\\n')\n",
    "        print(f\"Fold [{fold+1}/{k_folds}], Epoch [{epoch+1}/{num_epochs}], CIoU: {ciou_loss_per_epoch:.4f}\", end=\" --- \")\n",
    "        \n",
    "        # Validation Pipeline\n",
    "        model.eval()\n",
    "        ciou_total_batch_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                norm_labels = yolo_to_corners(labels, image_width=720, image_height=720)\n",
    "                outputs = yolo_to_corners(model(inputs), image_width=720, image_height=720)\n",
    "                \n",
    "                ciou_loss_per_batch = loss_function(outputs, norm_labels, 'mean')\n",
    "                ciou_total_batch_loss += ciou_loss_per_batch.item()\n",
    "        \n",
    "        val_ciou_loss = ciou_total_batch_loss / len(test_loader)\n",
    "        print(f\"Validation for Epoch [{epoch+1}/{num_epochs}], CIoU: {val_ciou_loss}\")\n",
    "        \n",
    "        # Save model for this epoch if it's the best so far\n",
    "        if val_ciou_loss < best_val_ciou_loss:\n",
    "            best_val_ciou_loss = val_ciou_loss\n",
    "            torch.save(model.state_dict(), f'E:\\Code\\CAMZ\\models\\model_fold_{fold + 1}_epoch_{epoch + 1}.pth')\n",
    "            print(f\"Saving best model for Fold {fold + 1} at Epoch {epoch + 1}\")\n",
    "\n",
    "\n",
    "        with open(history_csv_path, mode='a', newline=\"\") as file:\n",
    "            loss_writer = csv.writer(file)\n",
    "            loss_writer.writerow([epoch+1, ciou_loss_per_epoch, val_ciou_loss])\n",
    "\n",
    "    print(f\"Best Validation CIoU for Fold {fold + 1}: {best_val_ciou_loss:.4f}\")\n",
    "\n",
    "\n",
    "    fold_results.append((fold + 1, best_val_ciou_loss))\n",
    "\n",
    "# Print all results at the end\n",
    "print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "print(\"Fold\\tBest Validation CIoU Loss\")\n",
    "for fold, best_loss in fold_results:\n",
    "    print(f\"{fold}\\t{best_loss:.4f}\")\n",
    "\n",
    "# Print the average CIoU loss across folds\n",
    "avg_val_ciou_loss = sum(loss for _, loss in fold_results) / k_folds\n",
    "print(f\"\\nAverage Validation CIoU Loss Across All Folds: {avg_val_ciou_loss:.4f}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
